@Article{lakens_equivalence_2018,
  title = {Equivalence {Testing} for {Psychological} {Research}: {A} {Tutorial}},
  volume = {1},
  issn = {2515-2459, 2515-2467},
  shorttitle = {Equivalence {Testing} for {Psychological} {Research}},
  url = {http://journals.sagepub.com/doi/10.1177/2515245918770963},
  doi = {10.1177/2515245918770963},
  language = {en},
  number = {2},
  urldate = {2018-08-08TZ},
  journal = {Advances in Methods and Practices in Psychological Science},
  author = {Dani{\"e}l Lakens and Anne M. Scheel and Peder M. Isager},
  month = {jun},
  year = {2018},
  note = {https://osf.io/qamc6/},
  pages = {259--269},
}

@Article{maxwell_modeling_2018,
  title = {Modeling {Memory}: {Exploring} the {Relationship} {Between} {Word} {Overlap} and {Single} {Word} {Norms} when {Predicting} {Relatedness} {Judgments} and {Retrieval}},
  shorttitle = {Modeling {Memory}},
  url = {https://osf.io/qekad/},
  doi = {10.17605/osf.io/qekad},
  abstract = {This study examined the interactive relationship between semantic, thematic, and associative word pair strength in the prediction of item relatedness judgments and cued-recall performance. Previously, we found significant three-way interactions between associative, semantic, thematic word overlap when predicting participant judgment strength and recall performance (Maxwell \& Buchanan, 2018), expanding upon previous work by Maki (2007). In this study, we first seek to replicate findings from the original study using a novel stimuli set. Second, this study will further explore the nature of the structure of memory, by investigating the effects of single concept information (i.e., word frequency, concreteness, etc.) on relatedness judgments and recall accuracy. We hypothesize that associative, semantic, and thematic memory networks are interactive in their relationship to judgments and recall, even after controlling for base rates of single concept information, implying a set of interdependent memory systems used for both cognitive processes.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Nicholas Maxwell and Erin Buchanan},
  month = {jul},
  year = {2018},
  note = {https://osf.io/j7qtc/},
}

@Article{faulkenberry_task_2018,
  title = {Task instructions modulate unit–decade binding in two-digit number representation},
  issn = {0340-0727, 1430-2772},
  url = {http://link.springer.com/10.1007/s00426-018-1057-9},
  doi = {10.1007/s00426-018-1057-9},
  language = {en},
  urldate = {2018-08-08TZ},
  journal = {Psychological Research},
  author = {Thomas J. Faulkenberry and Alexander Cruise and Samuel Shaki},
  month = {jul},
  year = {2018},
  note = {https://github.com/tomfaulkenberry/twoDigitTaskManip},
}

@Article{barth_assumptions_2018,
  title = {Assumptions of the process-dissociation procedure are violated in implicit sequence learning.},
  issn = {1939-1285, 0278-7393},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xlm0000614},
  doi = {10.1037/xlm0000614},
  language = {en},
  urldate = {2018-08-08TZ},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  author = {Marius Barth and Christoph Stahl and Hilde Haider},
  month = {jul},
  year = {2018},
  note = {https://github.com/methexp/pdl2},
}

@Article{aust_memory-based_2018,
  title = {A memory-based judgment account of expectancy-liking dissociations in evaluative conditioning.},
  issn = {1939-1285, 0278-7393},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xlm0000600},
  doi = {10.1037/xlm0000600},
  language = {en},
  urldate = {2018-08-08TZ},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  author = {Frederik Aust and Julia M. Haaf and Christoph Stahl},
  month = {jul},
  year = {2018},
  note = {https://osf.io/vnmby/},
}

@Article{craddock_transcranial_2018,
  title = {Transcranial alternating current stimulation at 10 {Hz} modulates response bias in the {Somatic} {Signal} {Detection} {Task}},
  url = {http://biorxiv.org/lookup/doi/10.1101/330134},
  doi = {10.1101/330134},
  abstract = {Background: Ongoing, pre-stimulus oscillatory activity in the 8-13 Hz alpha range has been shown to correlate with both true and false reports of peri-threshold somatosensory stimuli. However, to directly test the role of such oscillatory activity in behaviour, it is necessary to manipulate it. Transcranial alternating current stimulation (tACS) offers a method of directly manipulating oscillatory brain activity using a sinusoidal current passed to the scalp.
Objective: We tested whether alpha tACS would change somatosensory sensitivity or response bias in a signal detection task in order to test whether alpha oscillations have a causal role in behaviour.
Methods: Active 10 Hz tACS or sham stimulation was applied using electrodes placed bilaterally at positions CP3 and CP4 of the 10-20 electrode placement system. Participants performed the Somatic Signal Detection Task (SSDT), in which they must detect brief somatosensory targets delivered at their detection threshold. These targets are sometimes accompanied by a light flash, which could also occur alone. 
Results: Active tACS did not modulate sensitivity to targets but did modulate response criterion. Specifically, we found that  active stimulation generally increased touch reporting rates, but particularly increased responding on light trials. Stimulation did not interact with the presence of touch, and thus increased both hits and false alarms. 
Conclusions: tACS stimulation increased reports of touch in a manner consistent with our observational reports, changing response bias, and consistent with a role for alpha activity in somatosensory detection.},
  urldate = {2018-06-06TZ},
  journal = {bioRxiv},
  author = {Matt Craddock and Ekaterini Klepousniotou and Wael El-Deredy and Ellen Poliakoff and Donna M. Lloyd},
  year = {2018},
  note = {},
}

@Article{buchanan_n400s_2018,
  title = {The {N}400's 3 {As}: {Association}, {Automaticity}, {Attenuation} (and {Some} {Semantics} {Too})},
  shorttitle = {The {N}400's 3 {As}},
  url = {https://osf.io/6w2se/},
  doi = {10.17605/osf.io/6w2se},
  abstract = {The N400 waveform carries new insight into the nature of linguistic processing and may shed light into the automaticity of priming word relationships. We investigated semantic and associative word pairs in classic lexical decision and letter search tasks to examine their differences in cognitive processing. Normed database information was used to create orthogonal semantic and associative word relationships to clearly define N400 waveforms and priming for these pairs. Participants showed N400 reduction for related word pairs, both semantic and associative, in comparison to unrelated word pairs for the lexical decision task, indicating automatic access for both types of relatedness. For a letter search task, the N400 showed differences between nonwords and other stimuli but no attenuation for related pairs. Response latency data indicated associative priming in both tasks with semantic priming also found in the letter search task. These results help discern possible automatic and controlled processes occurring during these tasks, as the N400 may show automatic processing during the lexical decision task, while the response latency data may provide evidence for controlled processing during the letter search task.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and John Scofield and Nathan Nunley},
  year = {2018},
  note = {https://osf.io/h5sd6/},
}

@Article{buchanan_lab:_2018,
  title = {The {LAB}: {Linguistic} {Annotated} {Bibliography}},
  shorttitle = {The {LAB}},
  url = {https://osf.io/h3bwx/},
  doi = {10.17605/osf.io/h3bwx},
  abstract = {In the era of big data, psycholinguistic research is flourishing with numerous publications that advance our knowledge of concept characteristics and ways to study them. This article presents the Linguistic Annotated Bibliography (LAB) as a searchable web portal to quickly and easily access reliable database norms, related programs, and variable calculations. These publications (*N* = 706) were coded by language, number of stimuli, stimuli type (i.e., words, pictures, symbols), keywords (i.e., frequency, semantics, valence), and other useful information. This tool not only allows researchers to search for the specific type of stimuli needed for experiments, but also permits the exploration of publication trends across 100 years of research. Details about the portal creation and use are outlined, as well as various analyses of change in publication rates and keywords. In general, advances in computation power have allowed for the increase in dataset size in the recent decades, in addition to an increase in the number of linguistic variables provided in each publication.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Kathrene Valentine and Nicholas Maxwell},
  year = {2018},
  note = {https://osf.io/9bcws/},
}

@Article{heycke_subliminal_2017,
  title = {Subliminal influence on preferences? {A} test of evaluative conditioning for brief visual conditioned stimuli using auditory unconditioned stimuli},
  volume = {4},
  copyright = {© 2017 The Authors.. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
  issn = {2054-5703},
  shorttitle = {Subliminal influence on preferences?},
  url = {http://rsos.royalsocietypublishing.org/content/4/9/160935},
  doi = {10.1098/rsos.160935},
  abstract = {In the field of evaluative conditioning (EC), two opposing theories—propositional single-process theory versus dual-process theory—are currently being discussed in the literature. The present set of experiments test a crucial prediction to adjudicate between these two theories: Dual-process theory postulates that evaluative conditioning can occur without awareness of the contingency between conditioned stimulus (CS) and unconditioned stimulus (US); in contrast, single-process propositional theory postulates that EC requires CS-US contingency awareness. In a set of three studies, we experimentally manipulate contingency awareness by presenting the CSs very briefly, thereby rendering it unlikely to be processed consciously. We address potential issues with previous studies on EC with subliminal or near-threshold CSs that limited their interpretation. Across two experiments, we consistently found an EC effect for CSs presented for 1000 ms and consistently failed to find an EC effect for briefly presented CSs. In a third pre-registered experiment, we again found evidence for an EC effect with CSs presented for 1000 ms, and we found some indication for an EC effect for CSs presented for 20 ms.},
  language = {en},
  number = {9},
  urldate = {2017-10-20TZ},
  journal = {Royal Society Open Science},
  author = {Tobias Heycke and Frederik Aust and Christoph Stahl},
  month = {sep},
  year = {2017},
  pages = {160935},
  note = {},
}

@Article{stahl_subliminal_2016,
  title = {Subliminal {Evaluative} {Conditioning}? {Above}-{Chance} {CS} {Identification} {May} {Be} {Necessary} and {Insufficient} for {Attitude} {Learning}},
  volume = {145},
  issn = {0096-3445},
  shorttitle = {Subliminal {Evaluative} {Conditioning}?},
  url = {http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=2016-31412-001&site=ehost-live},
  doi = {10.1037/xge0000191},
  abstract = {Previous research has claimed that evaluative conditioning (EC) effects may obtain in the absence of perceptual identification of conditioned stimuli (CSs). A recent meta-analysis suggested similar effect sizes for supra- and subliminal CSs, but this was based on a small body of evidence (k = 8 studies; Hofmann, De Houwer, Perugini, Baeyens, \& Crombez, 2010). We critically discuss this prior evidence, and then report and discuss 6 experimental studies that investigate EC effects for briefly presented CSs using more stringent methods. Across these studies, we varied CS duration, the presence or absence of masking, the presence or absence of a CS identification check, CS material, and the instructions communicated to participants. EC effects for longer-duration CSs were modulated by attention to the CS–US pairing. Across studies, we were consistently unable to obtain EC for briefly presented CSs. In most studies, this pattern was observed despite above-chance perceptual identification of the CSs. A meta-analysis conducted across the 27 experimental conditions supported the null hypothesis of no EC for perceptually unidentified CSs. We conclude that EC effects for briefly presented and masked CSs are either not robust, are very small, or are limited to specific conditions that remain to be identified (or any combination of these). (PsycINFO Database Record (c) 2016 APA, all rights reserved). (journal abstract)},
  urldate = {2016-06-28TZ},
  journal = {Journal of Experimental Psychology: General},
  author = {Christoph Stahl and Julia Haaf and Olivier Corneille},
  year = {2016},
  pages = {1107--1131},
  note = {},
}

@Article{papenberg_sequentially_2017,
  title = {Sequentially presented response options prevent the use of testwiseness cues in multiple-choice testing},
  volume = {59},
  url = {http://www.psychologie-aktuell.com/fileadmin/download/ptam/2-2017_20170627/06_Papenberg_.pdf},
  language = {en},
  number = {2},
  journal = {Psychological Test and Assessment Modeling},
  author = {Martin Papenberg and Sonja Willing and Jochen Musch},
  year = {2017},
  keywords = {🔍No DOI found},
  pages = {245--266},
  note = {},
}

@Article{mchugh_searching_2017,
  title = {Searching for {Moral} {Dumbfounding}: {Identifying} {Measurable} {Indicators} of {Moral} {Dumbfounding}},
  volume = {3},
  issn = {2474-7394},
  shorttitle = {Searching for {Moral} {Dumbfounding}},
  url = {http://www.collabra.org/article/10.1525/collabra.79/},
  doi = {10.1525/collabra.79},
  number = {1},
  urldate = {2018-05-25TZ},
  journal = {Collabra: Psychology},
  author = {Cillian McHugh and Marek McGann and Eric R. Igou and Elaine L. Kinsella},
  month = {oct},
  year = {2017},
  note = {https://osf.io/wm6vc/},
}

@Article{bergmann_promoting_2018,
  title = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses: {Insights} {From} {Language} {Acquisition} {Research}},
  issn = {00093920},
  shorttitle = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses},
  url = {http://doi.wiley.com/10.1111/cdev.13079},
  doi = {10.1111/cdev.13079},
  language = {en},
  urldate = {2018-05-25TZ},
  journal = {Child Development},
  author = {Christina Bergmann and Sho Tsuji and Page E. Piccinini and Molly L. Lewis and Mika Braginsky and Michael C. Frank and Alejandrina Cristia},
  month = {may},
  year = {2018},
  note = {https://osf.io/uhv3d/},
}

@Article{buchanan_perceived_2018,
  title = {Perceived {Grading} and {Student} {Evaluation} of {Instruction}},
  url = {https://osf.io/7x4uf/},
  doi = {10.17605/osf.io/7x4uf},
  abstract = {We analyzed student evaluations for 3,585 classes collected over 20 years to determine stability and evaluate the relationship of perceived grading to global evaluations, perceived fairness, and appropriateness of assignments. Using class as the unit of analysis, we found small evaluation reliability when professors taught the same course in the same semester, with much weaker correlations for differing courses. Expected grade and grading related questions correlated with overall evaluations of courses. Differences in course evaluations on expected grades, grading questions, and overall grades were found between full-time faculty and other types of instructors. These findings are expanded to a model of grading type questions mediating the relationship between expected grade and overall course evaluations with a moderating effect of type of instructor.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Becca Johnson and Arden Miller and David Stockburger and Marshall Beauchamp},
  year = {2018},
  note = {https://osf.io/jdpfs/},
}

@Article{heycke_two_2018,
  title = {Of two minds or one? {A} registered replication of {Rydell} et al. (2006)},
  volume = {0},
  url = {https://doi.org/10.1080/02699931.2018.1429389},
  doi = {10.1080/02699931.2018.1429389},
  number = {0},
  journal = {Cognition and Emotion},
  author = {Tobias Heycke and Sarah Gehrmann and Julia M. Haaf and Christoph Stahl},
  year = {2018},
  note = {https://osf.io/c57sr/},
  pages = {1--20},
}

@Article{sauer_observation_2017,
  title = {Observation oriented modeling revised from a statistical point of view},
  issn = {1554-3528},
  url = {http://link.springer.com/10.3758/s13428-017-0949-8},
  doi = {10.3758/s13428-017-0949-8},
  language = {en},
  urldate = {2018-05-25TZ},
  journal = {Behavior Research Methods},
  author = {Sebastian Sauer},
  month = {aug},
  year = {2017},
  note = {https://osf.io/6vhja/},
}

@Article{heycke_no_2018,
  title = {No {Evaluative} {Conditioning} {Effects} with {Briefly} {Presented} {Stimuli}},
  url = {https://psyarxiv.com/ujq4g/},
  doi = {10.17605/osf.io/ujq4g},
  abstract = {Evaluative Conditioning (EC) changes the preference towards a formerly neutral stimulus (Conditioned Stimulus; CS), by pairing it with a valent stimulus (Unconditioned Stimulus; US), in the direction of the valence of the US. When the CS is presented subliminally (i.e., too briefly to be consciously perceived), contingency awareness between CS and US can be ruled out. Hence, EC effects with subliminal CSs would support theories claiming that contingency awareness is not necessary for EC effects to occur. Recent studies reported the absence of EC with briefly presented CSs when both CS and US were presented in the visual modality, even though the CSs were identified at above-chance levels. Challenging this finding, Heycke and colleagues (2017) found some evidence for an EC effect with briefly presented visual stimuli in a cross-modal paradigm with auditory USs, but that study did not assess CS visibility. The present study attempted to replicate this EC effect with different stimuli and a CS visibility check. Overall EC for briefly presented stimuli was absent, and results from the visibility check show that an EC effect with briefly presented CSs was only found, when the CSs were identified at above-chance levels.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Tobias Heycke and Christoph Stahl},
  year = {2018},
  note = {https://osf.io/3dn7e/},
}

@Article{buchanan_methods_2018,
  title = {Methods to detect low quality data and its implication for psychological research},
  issn = {1554-3528},
  url = {http://link.springer.com/10.3758/s13428-018-1035-6},
  doi = {10.3758/s13428-018-1035-6},
  language = {en},
  urldate = {2018-05-25TZ},
  journal = {Behavior Research Methods},
  author = {Erin M. Buchanan and John E. Scofield},
  month = {mar},
  year = {2018},
  note = {https://osf.io/x6t8a/},
}

@Article{harms_making_2018,
  title = {Making '{Null} {Effects}' {Informative}: {Statistical} {Techniques} and {Inferential} {Frameworks}},
  shorttitle = {Making '{Null} {Effects}' {Informative}},
  url = {https://psyarxiv.com/48zca/},
  doi = {10.17605/osf.io/48zca},
  abstract = {The investigation of ‘null effects’ is important for cumulative knowledge generation in science. To draw informative conclusions from null-effects, re- searchers need to move beyond the incorrect interpretation of non-significant results in a null-hypothesis significance test as evidence for the absence of an effect. We explain how to statistically evaluate null-results using equiv- alence tests, Bayesian estimation, and Bayes factors. A worked example demonstrates how to apply these statistical tools, and interpret the results. Finally, we explain how no statistical approach can actually prove that the null-hypothesis is true, and briefly discuss the philosophical differences be- tween statistical approaches to examine null-effects. The increasing avail- ability of software and online tools to perform equivalence tests, Bayesian estimation, and Bayes factors make it timely and feasible to move beyond traditional null-hypothesis tests, and allow researchers to draw more infor- mative conclusions about null-effects.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Christopher Harms and Daniel Lakens},
  year = {2018},
  note = {https://osf.io/wptju/},
}

@Article{maxwell_investigating_2018,
  title = {Investigating the {Interaction} between {Associative}, {Semantic}, and {Thematic} {Database} {Norms} for {Memory} {Judgments} and {Retrieval}},
  url = {https://osf.io/fcesn/},
  doi = {10.17605/osf.io/fcesn},
  abstract = {This study examined the interactive relationship between semantic, thematic, and associative word pair strength in the prediction of judgments and cued-recall performance. One hundred and twelve participants were recruited from Amazon's Mechanical Turk. They were shown word pairs of varying relatedness and were then asked to judge these word pairs for their semantic, thematic, and associative strength. After completing a distractor task, participants then completed a cued recall task. The data was then analyzed through multilevel modeling, incorporating a logistic regression to account for the binary nature of the recall.  Four hypotheses were tested. First, we sought to expand previous work on memory judgments to include three types of judgments of memory, while also replicating bias and sensitivity findings. Next, we tested for an interaction between the three database norms (FSG, COS, and LSA) when predicting participant judgments. Third, we extended this analysis to test for interactions between the three database norms when predicting recall. In both our second and third hypothesis, significant three-way interactions were found between FSG, COS, and LSA when predicting judgments or recall. For low semantic feature overlap, thematic and associative strength were competitive; as thematic strength increased, associative predictiveness decreased. However, this trend reversed for high semantic feature overlap, wherein thematic and associative strength were complimentary as both set of simple slopes increased together. Finally, we showed that judgment-database slopes were predictive of recall.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Nicholas Maxwell and Erin Buchanan},
  year = {2018},
  note = {https://osf.io/y8h7v/},
}

@Article{aust_incremental_2016,
  title = {Incremental validity of {Useful} {Field} of {View} subtests for the prediction of instrumental activities of daily living},
  volume = {38},
  issn = {1380-3395, 1744-411X},
  url = {https://www.tandfonline.com/doi/full/10.1080/13803395.2015.1125453},
  doi = {10.1080/13803395.2015.1125453},
  language = {en},
  number = {5},
  urldate = {2018-05-25TZ},
  journal = {Journal of Clinical and Experimental Neuropsychology},
  author = {Frederik Aust and Jerri D. Edwards},
  month = {may},
  year = {2016},
  pages = {497--515},
  note = {},
}

@Article{pollet_how_2018,
  title = {How diverse are the samples used in the journals ‘{Evolution} \& {Human} {Behavior}’ and ‘{Evolutionary} {Psychology}’?},
  url = {https://osf.io/7h24p/},
  doi = {10.17605/osf.io/7h24p},
  abstract = {The psychological literature is regularly criticised on the basis that limited sampling quality might restrict the inferences that can be made. Specifically, researchers have raised concerns regarding over-reliance upon samples from Western Educated Industrialised Rich and Democratic (WEIRD) societies, and in particular from university students. In addition, a growing tendency to collect data using anonymous and unsupervised online surveys might introduce problems of data quality. Studies from evolutionary psychology often seek to uncover aspects of evolved universal characteristics, and so criticisms of sample diversity would be a particular problem for the field. Here, we empirically examine the samples used in the 2015 volumes of ‘Evolution \& Human Behavior’ (57 articles) and ‘Evolutionary Psychology’ (43 articles). Our database consists of 166 samples of humans (median sample size= 206). The majority of samples were either online or student samples (60\% of samples), followed by other adult Western samples (19\%). 129 of the samples were classified as ‘Western’ (78\%, Europe/North America/Australia). The remaining samples were predominantly from Asia (N= 26; 16\%, mostly Japan). Only a small fraction of the samples was classified as cross-cultural (5), South American (3) or African (2). The median sample size did not significantly differ between continents, but online samples (both paid and unpaid) were typically larger than samples sourced offline. While it seems that the samples used are more diverse than those that have been reported in reviews of the literature from social and developmental psychology, it also apparent that the majority of samples remain WEIRD. We discuss the implications for Evolutionary Psychology as a discipline.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Thomas V. Pollet and Tamsin Saxton},
  year = {2018},
  note = {},
}

@Article{beaton_generalization_2018,
  title = {Generalization of the minimum covariance determinant algorithm for categorical and mixed data types},
  url = {http://biorxiv.org/lookup/doi/10.1101/333005},
  doi = {10.1101/333005},
  abstract = {The minimum covariance determinant (MCD) algorithm is one of the most common techniques to detect anomalous or outlying observations. The MCD algorithm depends on two features of multivariate data: the determinant of a matrix (i.e., geometric mean of the eigenvalues) and Mahalanobis distances (MD). While the MCD algorithm is commonly used, and has many extensions, the MCD is limited to analyses of quantitative data and more specifically data assumed to be continuous. One reason why the MCD does not extend to other data types such as categorical or ordinal data is because there is not a well-defined MD for data types other than continuous data. To address the lack of MCD-like techniques for categorical or mixed data we present a generalization of the MCD. To do so, we rely on a multivariate technique called correspondence analysis (CA). Through CA we can define MD via singular vectors and we can compute the determinant from CA's eigenvalues. Here we define and illustrate a generalized MCD on categorical data and then show how our generalized MCD extends beyond categorical data to accommodate mixed data types (e.g., categorical, ordinal, and continuous). We illustrate this generalized MCD on data from two large scale projects: the Ontario Neurodegenerative Disease Research Initiative (ONDRI) and the Alzheimer's Disease Neuroimaging Initiative (ADNI) with data such as genetics (categorical), clinical instruments and surveys (categorical or ordinal), and neuroimaging (continuous) data. We also make R code and toy data available in order to illustrate our generalized MCD.},
  urldate = {2018-06-11TZ},
  journal = {bioRxiv},
  author = {Derek Beaton and Kelly M. Sunderland and Brian Levine and Jennifer Mandzia and Mario Masellis and Richard H. Swartz and Angela K. Troyer and Malcolm A. Binns and Herv{\a'e} Abdi and Stephen C. Strother},
  year = {2018},
  note = {},
}

@Article{rouder_theories_2018,
  title = {From theories to models to predictions: {A} {Bayesian} model comparison approach},
  volume = {85},
  issn = {0363-7751, 1479-5787},
  shorttitle = {From theories to models to predictions},
  url = {https://www.tandfonline.com/doi/full/10.1080/03637751.2017.1394581},
  doi = {10.1080/03637751.2017.1394581},
  language = {en},
  number = {1},
  urldate = {2018-05-25TZ},
  journal = {Communication Monographs},
  author = {Jeffrey N. Rouder and Julia M. Haaf and Frederik Aust},
  month = {jan},
  year = {2018},
  pages = {41--56},
  note = {},
}

@Article{jordan_focus_2018,
  title = {Focus on the {Target}: {The} {Role} of {Attentional} {Focus} in {Decisions} about {War}},
  shorttitle = {Focus on the {Target}},
  url = {https://osf.io/9fgu8/},
  doi = {10.17605/osf.io/9fgu8},
  abstract = {Legislative bodies have very important roles and understanding the psychology of their decision-making processes is a useful area of study. We add to this area by examining Congressional decision making when it comes to war measures and exploring where lawmakers' attention is focused when debating these issues. The present study hypothesized that legislators who support war measures focus more on other people and on the present circumstances. Speeches were obtained pertaining to the decisions for the U.S. to take military action in Kosovo, Iraq, and Libya. While we found mixed results depending on the circumstances of a specific conflict, we demonstrate how automated language analysis can be combined with voting records to better understand behavioral action, such as legislative decision.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Kayla Jordan and Erin Buchanan and William Padfield},
  year = {2018},
  note = {https://osf.io/r8qp2/},
}

@Article{stahl_false_2016,
  title = {False memory for perceptually similar but conceptually distinct line drawings},
  url = {https://psyarxiv.com/zr7m8/},
  doi = {10.17605/osf.io/zr7m8},
  abstract = {Whereas most false memory effects for pictorial material are thought to be based on semantic or conceptual similarity, some findings, based on novel visual material, have been attributed solely to perceptual similarity.  However, alternative accounts of these perceptual effects in terms of associative and/or conceptual processes have been proposed.  We report four experiments that address these points of criticism, using pairs of perceptually similar but conceptually distinct line drawings of objects (e.g., banana -- crescent). Similar lures were judged old more often than unrelated items, and confidence for false alarms was greater for similar lures than for unrelated items. This perceptual false memory effect was not modulated by rotation of stimuli between study and test, was unaffected by retention interval (0 vs. 20 min), and was obtained regardless of response format (old/new and old/similar/new). These findings rule out the criticism of previous perceptual false memory effects and more conclusively demonstrate false memory on the basis of perceptual similarity.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Christoph Stahl and Laura Henze and Frederik Aust},
  year = {2016},
  note = {https://osf.io/jxm7z/},
}

@Article{stahl_evaluative_2016,
  title = {Evaluative {Conditioning} with {Simultaneous} and {Sequential} {Pairings} {Under} {Incidental} and {Intentional} {Learning} {Conditions}},
  volume = {34},
  issn = {0278-016X},
  url = {http://guilfordjournals.com/doi/10.1521/soco.2016.34.5.382},
  doi = {10.1521/soco.2016.34.5.382},
  abstract = {Two studies investigated whether evaluative conditioning (EC) is modulated by pairing schedule (simultaneous vs. sequential) and by the nature of the orienting task. We tested the prediction that simultaneous (but not sequential) EC is obtained without awareness, and whether this modulatory effect supports dual-process theories of attitude acquisition. Results replicated the finding of a simultaneous EC effect in the absence of unconditioned stimulus (US) identity memory; in contrast, sequential EC effects depended on the presence of US identity memory. Yet, both EC effects were larger in the presence than in the absence of US identity memory and depended on the presence of US valence memory. Whereas the findings are consistent with dual learning processes, they can also be accounted for by a single learning process. Conceptual, theoretical, and methodological requirements for distinguishing between single- and dual-process models of EC are discussed.},
  number = {5},
  urldate = {2017-03-29TZ},
  journal = {Social Cognition},
  author = {Christoph Stahl and Tobias Heycke},
  year = {2016},
  pages = {382--412},
  note = {},
}

@Article{buchanan_english_2018,
  title = {English {Semantic} {Feature} {Production} {Norms}: {An} {Extended} {Database} of 4,436 {Concepts}},
  shorttitle = {English {Semantic} {Feature} {Production} {Norms}},
  url = {https://osf.io/gxbf4/},
  doi = {10.17605/osf.io/gxbf4},
  abstract = {The largest limiting factor in understanding memory and language networks is often the availability of normed stimuli to use and explore in experimental studies. In this study, we expand on three previous semantic feature overlap norms to over 4,000 cue stimuli ranging from nouns, verbs, adjectives, and other parts of speech. Participants in the norming study were asked to provide feature components of each cue stimuli, which were combined with the previous research using semantic feature production procedures. In addition to expanding previous research, this project explores different semantic overlap measurements by coding each word feature listed by root and affixes to determine different strengths of feature overlap. All information is provided in a searchable database for easy access and utilization for future researchers when designing experiments. The final database of cue-target pairs was paired with the Semantic Priming Project to examine the relation of feature overlap statistics on semantic priming in tandem with other psycholinguistic variables, such as association and thematics.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Kathrene Valentine and Nicholas Maxwell},
  year = {2018},
  note = {https://osf.io/cjyzw/},
}

@Article{urry_effect_2018,
  title = {Effect of {Disgust} on {Judgments} of {Moral} {Wrongness}: {A} {Replication} of {Eskine}, {Kacinik}, and {Prinz} (2011)},
  url = {https://osf.io/fu384/},
  journal = {at Tufts University - Spring, 2017},
  author = {Heather L. Urry and Erin Sifre and Justin Song and Hannah Steinberg and Michelle Bornstein and Joan Kim and Martha Rimniceanu and Marissa Sashihara and Annie Artz and Kathy Chin and Eliza Flynn and Elim Na and Mel Andrews},
  month = {jan},
  year = {2018},
  note = {https://osf.io/ddmkm},
  keywords = {🔍No DOI found},
}

@Article{buchanan_does_2018,
  title = {Does the {Delivery} {Matter}? {Examining} {Randomization} at the {Item} {Level}},
  shorttitle = {Does the {Delivery} {Matter}?},
  url = {https://osf.io/p93df/},
  doi = {10.17605/osf.io/p93df},
  abstract = {Scales that are psychometrically sound, meaning those that meet established standards regarding reliability and validity when measuring one or more constructs of interest, are customarily evaluated based on a set modality (i.e., computer or paper) and administration (fixed-item order). Deviating from an established administration profile could result in non-equivalent response patterns, indicating the possible evaluation of a dissimilar construct. Randomizing item administration may alter or eliminate these effects. Therefore, we examined the differences in scale relationships for randomized and nonrandomized computer delivery for two scales measuring meaning/purpose in life. These scales have questions about suicidality, depression, and life goals that may cause item reactivity (i.e. a changed response to a second item based on the answer to the first item). Results indicated that item randomization does not alter scale psychometrics for meaning in life scales, which implies that results are comparable even if researchers implement different delivery modalities.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Riley Foreman and Becca Johnson and Jeffrey Pavlacic and Rachel Swadley and Stefan Schulenberg},
  year = {2018},
  note = {https://osf.io/gvx7s/},
}

@Article{stahl_distorted_2015,
  title = {Distorted estimates of implicit and explicit learning in applications of the process-dissociation procedure to the {SRT} task},
  volume = {37},
  doi = {10.1016/j.concog.2015.08.003},
  journal = {Consciousness and Cognition},
  author = {Christoph Stahl and Marius Barth and Hilde Haider},
  year = {2015},
  pages = {27--43},
  note = {},
}

@Article{heino_bayesian_2018,
  title = {Bayesian evaluation of behavior change interventions: a brief introduction and a practical example},
  volume = {6},
  issn = {2164-2850},
  shorttitle = {Bayesian evaluation of behavior change interventions},
  url = {https://www.tandfonline.com/doi/full/10.1080/21642850.2018.1428102},
  doi = {10.1080/21642850.2018.1428102},
  language = {en},
  number = {1},
  urldate = {2018-05-25TZ},
  journal = {Health Psychology and Behavioral Medicine},
  author = {Matti T. J. Heino and Matti Vuorre and Nelli Hankonen},
  month = {jan},
  year = {2018},
  note = {https://zenodo.org/record/1209814\#.Wvy3H4jOVGM},
  pages = {49--78},
}

@Article{haaf_developing_2017,
  title = {Developing constraint in bayesian mixed models.},
  volume = {22},
  issn = {1939-1463, 1082-989X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000156},
  doi = {10.1037/met0000156},
  language = {en},
  number = {4},
  urldate = {2018-05-25TZ},
  journal = {Psychological Methods},
  author = {Julia M. Haaf and Jeffrey N. Rouder},
  month = {dec},
  year = {2017},
  note = {https://github.com/PerceptionAndCognitionLab/ctx-indiff},
  pages = {779--798},
}

@Article{hardwicke_data_2018,
  title = {Data availability, reusability, and analytic reproducibility: {Evaluating} the impact of a mandatory open data policy at the journal {Cognition}},
  shorttitle = {Data availability, reusability, and analytic reproducibility},
  url = {https://osf.io/preprints/bitss/39cfb/},
  doi = {10.17605/osf.io/39cfb},
  abstract = {Access to research data is a critical feature of an efficient, progressive, and ultimately self-correcting scientific ecosystem. But the extent to which in-principle benefits of data sharing are realized in practice is unclear. Crucially, it is largely unknown whether published findings can be reproduced by repeating reported analyses upon shared data ({"}analytic reproducibility{"}). To investigate, we conducted an observational evaluation of a mandatory open data policy introduced at the journal Cognition. Interrupted time-series analyses indicated a substantial post-policy increase in data available statements (104/417, 25\% pre-policy to 136/174, 78\% post-policy), and data that were in-principle reusable (23/104, 22\% pre-policy to 85/136, 62\%, post-policy). However, for 35 articles with in-principle reusable data, the analytic reproducibility of target outcomes related to key findings was poor: 11 (31\%) cases were reproducible without author assistance, 11 (31\%) cases were reproducible only with author assistance, and 13 (37\%) cases were not fully reproducible despite author assistance. Importantly, original conclusions did not appear to be seriously impacted. Mandatory open data policies can increase the frequency and quality of data sharing. However, suboptimal data curation, unclear analysis specification, and reporting errors can impede analytic reproducibility, undermining the utility of data sharing and the credibility of scientific findings.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Tom Hardwicke and Maya Mathur and Kyle MacDonald and Gustav Nilsonne and George Banks and Mallory Kidwell and Alicia {Hofelich Mohr} and Elizabeth Clayton and Erica Yoon and Michael Tessler and Richie Lenne and Sara Altman and Bria Long and Michael Frank},
  year = {2018},
  note = {https://osf.io/wn8fd/},
}

@Article{heyman_can_2018,
  title = {Can prediction-based distributional semantic models predict typicality?},
  doi = {10.17605/osf.io/59xtd},
  abstract = {Recent advances in the field of computational linguistics have led to the development of various prediction-based models of semantics. These models seek to infer word representations from large text collections by predicting target words from neighboring words (or vice versa). The resulting representations are vectors in a continuous space, collectively called word embeddings. Although psychological plausibility was not a primary concern for the developers of predictive models, it has been the topic of several recent studies in the field of psycholinguistics. That is, word embeddings have been linked to similarity ratings, word associations, semantic priming, word recognition latencies, etcetera. Here, we build on this work by investigating category structure. More specifically, we first obtained a prototype for a number of common categories (e.g., birds, fruit, vehicles,...) either  by averaging across exemplar vectors (e.g., robin, dove, sparrow,...) or by relying on the representation of the label itself (e.g., bird). Then, we correlated the cosine similarity between an exemplar and its prototype with human typicality judgments. The resulting correlations turned out to be disappointingly low, especially given the enthusiasm surrounding predictive models.},
  journal = {PsyArXiv},
  author = {Tom Heyman and Geert Heyman},
  year = {2018},
  note = {https://osf.io/nkfjy/},
}

@Article{buchanan_bulletproof_2018,
  title = {Bulletproof {Bias}? {Considering} the {Type} of {Data} in {Common} {Proportion} of {Variance} {Effect} {Sizes}},
  shorttitle = {Bulletproof {Bias}?},
  url = {https://osf.io/cs4vy/},
  doi = {10.17605/osf.io/cs4vy},
  abstract = {As effect sizes gain ground as important indicators of practical significance and as a meta-analytic tool, we must critically understand their limitations and biases. This project expands on research by @Okada2013, which highlighted the positive bias of eta squared and suggested the use of omega squared or epsilon for their lack of bias. These variance overlap measures were examined for potential bias in different data scenarios (i.e. truncated and Likert type data) to elucidate differences in bias from previous research. We found that data precision and truncation affected effect size bias, often lowering the bias in eta squared. This work expands our understanding of bias on variance overlap measures and allows researchers to make an informed choice about the type of effect to report given their research study. Implications for sample size planning and power are also discussed.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and John Scofield},
  year = {2018},
  note = {https://osf.io/urd8q/},
}

@Article{valentine_beyond_2018,
  title = {Beyond p-values: {Utilizing} {Multiple} {Estimates} to {Evaluate} {Evidence}},
  shorttitle = {Beyond p-values},
  url = {https://osf.io/9hp7y/},
  doi = {10.17605/osf.io/9hp7y},
  abstract = {Null hypothesis significance testing is frequently cited as a threat to the validity and reproducibility of the social sciences. While many individuals suggest we should focus on altering the *p*-value at which we deem an effect significant, we believe this suggestion is short-sighted. Alternative procedures (i.e., Bayesian analyses and Observation Oriented Modeling) can be more powerful and meaningful to our discipline. However, these methodologies are less frequently utilized and are rarely discussed in combination with NHST. Herein, we compare the possible interpretations of three analyses (ANOVA, Bayes Factor, and an Ordinal Pattern Analysis) in various data environments using a simulation study. The simulation generated 20000 unique datasets which varied sample size (*N*s of 10, 30, 100, 500, 1000), and effect sizes (*d*s of 0.10, 0.20, 0.05, 0.80). Through this simulation, we find that changing the threshold at which *p*-values are considered significant has little to no effect on conclusions. Further, we find that evaluating multiple estimates as evidence of an effect can allow for a more robust and nuanced report of findings. These findings suggest the need to redefine evidentiary value and reporting practices.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Kathrene Valentine and Erin Buchanan and John Scofield and Marshall Beauchamp},
  year = {2018},
  note = {https://osf.io/u9hf4/},
}

@Article{buchanan_extension_2018,
  title = {An {Extension} of the {QWERTY} {Effect}: {Not} {Just} the {Right} {Hand}, {Expertise} and {Typability} {Predict} {Valence} {Ratings} of {Words}},
  shorttitle = {An {Extension} of the {QWERTY} {Effect}},
  url = {https://osf.io/k7dx5/},
  doi = {10.31219/osf.io/k7dx5},
  abstract = {Typing is a ubiquitous daily action for many individuals; yet, research on how these actions have changed our perception of language is limited. The QWERTY effect is an increase in valence ratings for words typed more with the right hand on a traditional keyboard (Jasmin \& Casasanto, 2012). Although this finding is intuitively appealing given both right handed dominance and the smaller number of letters typed with the right hand, extension and replication of the right side advantage is warranted. The present paper reexamined the QWERTY effect within the embodied cognition framework (Barsalou, 1999) and found that the right side advantage is replicable to new valence stimuli, as well as experimental manipulation. Further, when examining expertise, right side advantage interacted with typing speed and typability (i.e., alternating hand keypresses or finger switches) portraying that both skill and our procedural actions play a role in judgment of valence on words.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Erin Buchanan and Kathrene Valentine},
  year = {2018},
  note = {https://osf.io/zs2qj/},
}

@Article{derringer_simple_2018,
  title = {A simple correction for non-independent tests},
  url = {https://psyarxiv.com/f2tyw/},
  doi = {10/gdrbxc},
  abstract = {Psychologists wrestle with how to best handle multiple comparisons, while maintaining a balance between false positives and false negatives. Undercorrection, such as ignoring the presence of multiple comparisons altogether, is known to yield an unacceptably high rate of false positives. Overcorrection, such as treating all tests as independent when they are not, results in overly conservative evaluations of statistical significance. This tutorial demonstrates \$M\_\{eff\}\$ correction, a method for adjusting statistical significance thresholds for multiple comparisons, without the assumption of independence of tests. This method, in which the effective number of tests (\$M\_\{eff\}\$) is estimated from the correlations among the variables being tested, was developed and validated in the field of genetics, but is based on statistical concepts (eigenvalues) that are very familiar to psychologists. \$M\_\{eff\}\$ correction can be applied in psychological research to balance the necessity of correction for multiple comparisons with the concerns that arise from complex, correlated tests.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Jaime Derringer},
  year = {2018},
  note = {https://osf.io/re5w2/},
}

@Article{pavlacic_meta-analysis_2018,
  title = {A {Meta}-{Analysis} of {Expressive} {Writing} on {Positive} {Psychology} {Variables} and {Traumatic} {Stress}},
  url = {https://osf.io/u98cw/},
  doi = {10.17605/osf.io/u98cw},
  abstract = {Emotional expression has been shown to be benficial for promoting both positive psychological and physical health outcomes. Unfortunately, inhibiting emotions can lead to impairments in physical and psychological health. James Pennebaker showed that expressive writing is an effective form of emotional expression, and he and others have used expressive writing as an experimental manipulation to gauge its effectiveness in treating a wide variety of health-related and psychological outcomes. While many studies have been conducted that examine the effectiveness of expressive writing across such outcomes, a considerable amount of these studies tend to neglect necessary considerations such as power and meaningfulness of respective effect sizes. Four previous meta-analyses have been conducted that examine expressive writing's affect on psychological outcomes, however, these studies focus on the experimental versus control group effect size. Thus, our meta-analysis sought to examine the effectiveness of an expressive writing intervention on only the experimental conditions in studies measuring posttraumatic growth, posttraumatic stress, and quality of life using random effects models. Results indicated a small overall effect size for posttraumatic stress and negligible to small effect sizes for posttraumatic growth and quality of life. Implications for future research design and interpretation of published research are discussed.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Jeffrey Pavlacic and Erin Buchanan and Nicholas Maxwell and Tabetha Hopke and Stefan Schulenberg},
  year = {2018},
  note = {https://osf.io/4mjqt/},
}

@Article{hardwicke_mapping_2018,
  title = {Mapping the {Universe} of {Registered} {Reports}},
  url = {https://osf.io/preprints/bitss/fzpcy/},
  doi = {10.31222/osf.io/fzpcy},
  abstract = {Selection pressures for significant results may infuse bias into the research process. We evaluated the implementation of one innovation designed to mitigate this bias, ‘Registered Reports’, where study protocols are peer-reviewed and granted in-principle acceptance (IPA) for publication before the study has been conducted. As of February 2018, 91 journals had adopted Registered Reports and 91 Final Reports had been published. Psychology journals are the principal adopters, but expansion has begun into medicine, social science, and other fields. Among 29 journals that responded to a survey, 334 protocols had been submitted to them, 87 had been granted IPA and 32 Final Reports had been published or were in press as of July 2017. We encountered several sub-optimal implementation practices, including non-availability of IPA protocols, and diverse approaches to protocol registration in the absence of a single central registry. Registered Reports should be iteratively evaluated and improved to ensure maximal benefits.},
  urldate = {2018-05-25TZ},
  journal = {PsyArXiv},
  author = {Tom Hardwicke and john Ioannidis},
  year = {2018},
  note = {https://osf.io/7dpwb/},
}

@Article{stevens_predicting_2018,
  title = {Predicting similarity judgments in intertemporal choice with machine learning},
  volume = {25},
  issn = {1069-9384, 1531-5320},
  url = {http://link.springer.com/10.3758/s13423-017-1398-1},
  doi = {10/gdfghk},
  language = {en},
  number = {2},
  urldate = {2018-07-08TZ},
  journal = {Psychonomic Bulletin \& Review},
  author = {Jeffrey R. Stevens and Leen-Kiat Soh},
  month = {apr},
  year = {2018},
  note = {},
  pages = {627--635},
}
